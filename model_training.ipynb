{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HAeiPvmbQ-12"
   },
   "source": [
    "# Installing libraries for colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nRXrfsOKprtd",
    "outputId": "523501f3-f7e1-41db-947f-fe665a8e2ff8",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Download the python packages, note that we use other packages that you might also need to install if you run\n",
    "# this notebook on your machine. If you run it on colab, these are the only packages that need to be pip installed\n",
    "!pip install yfinance --upgrade --no-cache-dir\n",
    "!pip install ta\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4DMMgFMAbpYy"
   },
   "source": [
    "# Downloading and setting up the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "8fOyZxnRpu19"
   },
   "outputs": [],
   "source": [
    "# yfinance is the API and ta is a technical analysis tool\n",
    "import yfinance as yf\n",
    "import ta\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# For data manupilation\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from data_utils import pull_stock_data, pull_stock_indicators, cleaning_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1tqzRHqVSD5s",
    "outputId": "6b6c0500-4466-44bb-e2b9-702720fe1b06"
   },
   "outputs": [],
   "source": [
    "# Obtaining the SNP 500 companies\n",
    "stock_dfs = {}\n",
    "all_tickers = pd.read_html('https://en.wikipedia.org/wiki/List_of_S%26P_500_companies')[0]\n",
    "all_stocks = all_tickers.Symbol.to_list()\n",
    "\n",
    "# Obtaining most important company's stocks\n",
    "# These are subdivided into categories\n",
    "tech = ['MSFT','AAPL','NVDA', 'GOOGL', 'GOOG', 'AMZN', 'META', 'AVGO', 'TSLA','ORCL','CRM','NFLX','AMD','QCOM','ADBE','ASML','ADI','DELL']\n",
    "pharma = ['LLY',\"JNJ\",'MRK','ABBV','TMO','MRK','MRNA','PFE',\"CVS\"]\n",
    "finance = ['BRK-B','JPM','V','MA','BAC','WFC', 'ACN', 'MS','BLK','GS',\"PYPL\"]\n",
    "defense = ['BA','LMT','RTX','GE','NOC']\n",
    "energy = ['XOM','CVX','LIN','SBGSY']\n",
    "retail = ['WMT', \"UNH\", \"PG\", 'COST', 'HD','KO','PEP','MCD','LVMUY', 'NSRGY','TM', 'LRLCY', 'GM', 'BAB','NKE',\"T\",'F']\n",
    "\n",
    "all_stocks = tech+pharma+finance+defense+energy+retail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78sGmzrkvtV-",
    "outputId": "ecb4ff13-2834-4bac-aa41-522f3c52f4da",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "# Calling the functions to import the stock data -> to see functions go to data_utils.py file\n",
    "full_stock_data = pull_stock_data(all_stocks, '2022-06-01', '2024-05-01', '1h')\n",
    "full_stock_data = pull_stock_indicators(full_stock_data)\n",
    "full_stock_data = cleaning_data(full_stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 995
    },
    "id": "TRcefY4i7qk5",
    "outputId": "588dc926-94f6-405a-fa22-35ed05d362fb",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>SMA_20</th>\n",
       "      <th>SMA_50</th>\n",
       "      <th>%K</th>\n",
       "      <th>%D</th>\n",
       "      <th>RSI</th>\n",
       "      <th>BB_Middle</th>\n",
       "      <th>BB_Upper</th>\n",
       "      <th>BB_Lower</th>\n",
       "      <th>MACD</th>\n",
       "      <th>MACD_Signal</th>\n",
       "      <th>ATR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2022-06-10 09:30:00-04:00</th>\n",
       "      <td>140.190002</td>\n",
       "      <td>140.759995</td>\n",
       "      <td>137.460007</td>\n",
       "      <td>137.490005</td>\n",
       "      <td>137.490005</td>\n",
       "      <td>23421485</td>\n",
       "      <td>146.779439</td>\n",
       "      <td>147.263031</td>\n",
       "      <td>0.246150</td>\n",
       "      <td>0.429504</td>\n",
       "      <td>15.611410</td>\n",
       "      <td>146.779439</td>\n",
       "      <td>152.291020</td>\n",
       "      <td>141.267858</td>\n",
       "      <td>-1.466908</td>\n",
       "      <td>-0.547692</td>\n",
       "      <td>1.526065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10 10:30:00-04:00</th>\n",
       "      <td>137.489899</td>\n",
       "      <td>138.539001</td>\n",
       "      <td>137.270004</td>\n",
       "      <td>137.399994</td>\n",
       "      <td>137.399994</td>\n",
       "      <td>13497913</td>\n",
       "      <td>146.285439</td>\n",
       "      <td>147.027887</td>\n",
       "      <td>1.054255</td>\n",
       "      <td>0.754015</td>\n",
       "      <td>15.499934</td>\n",
       "      <td>146.285439</td>\n",
       "      <td>153.137159</td>\n",
       "      <td>139.433719</td>\n",
       "      <td>-1.930529</td>\n",
       "      <td>-0.824260</td>\n",
       "      <td>1.507703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10 11:30:00-04:00</th>\n",
       "      <td>137.410995</td>\n",
       "      <td>138.070007</td>\n",
       "      <td>137.289993</td>\n",
       "      <td>137.975006</td>\n",
       "      <td>137.975006</td>\n",
       "      <td>7736991</td>\n",
       "      <td>145.775689</td>\n",
       "      <td>146.813787</td>\n",
       "      <td>6.109205</td>\n",
       "      <td>2.469870</td>\n",
       "      <td>19.456611</td>\n",
       "      <td>145.775689</td>\n",
       "      <td>153.457423</td>\n",
       "      <td>138.093955</td>\n",
       "      <td>-2.225894</td>\n",
       "      <td>-1.104586</td>\n",
       "      <td>1.455725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10 12:30:00-04:00</th>\n",
       "      <td>137.979996</td>\n",
       "      <td>138.210007</td>\n",
       "      <td>137.460007</td>\n",
       "      <td>138.089996</td>\n",
       "      <td>138.089996</td>\n",
       "      <td>6411832</td>\n",
       "      <td>145.242439</td>\n",
       "      <td>146.614387</td>\n",
       "      <td>7.321360</td>\n",
       "      <td>4.828273</td>\n",
       "      <td>20.260719</td>\n",
       "      <td>145.242439</td>\n",
       "      <td>153.483210</td>\n",
       "      <td>137.001667</td>\n",
       "      <td>-2.422766</td>\n",
       "      <td>-1.368222</td>\n",
       "      <td>1.405316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-06-10 13:30:00-04:00</th>\n",
       "      <td>138.089996</td>\n",
       "      <td>138.740005</td>\n",
       "      <td>137.729996</td>\n",
       "      <td>137.960007</td>\n",
       "      <td>137.960007</td>\n",
       "      <td>7293856</td>\n",
       "      <td>144.708189</td>\n",
       "      <td>146.406943</td>\n",
       "      <td>6.160738</td>\n",
       "      <td>6.530434</td>\n",
       "      <td>20.017429</td>\n",
       "      <td>144.708189</td>\n",
       "      <td>153.371900</td>\n",
       "      <td>136.044477</td>\n",
       "      <td>-2.559770</td>\n",
       "      <td>-1.606532</td>\n",
       "      <td>1.377080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 11:30:00-04:00</th>\n",
       "      <td>173.869904</td>\n",
       "      <td>174.199905</td>\n",
       "      <td>173.604996</td>\n",
       "      <td>173.836594</td>\n",
       "      <td>173.836594</td>\n",
       "      <td>3446845</td>\n",
       "      <td>172.079618</td>\n",
       "      <td>168.986474</td>\n",
       "      <td>67.932656</td>\n",
       "      <td>70.962925</td>\n",
       "      <td>64.151716</td>\n",
       "      <td>172.079618</td>\n",
       "      <td>176.451501</td>\n",
       "      <td>167.707735</td>\n",
       "      <td>1.488587</td>\n",
       "      <td>1.438002</td>\n",
       "      <td>1.206533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 12:30:00-04:00</th>\n",
       "      <td>173.839996</td>\n",
       "      <td>173.929993</td>\n",
       "      <td>173.220001</td>\n",
       "      <td>173.275299</td>\n",
       "      <td>173.275299</td>\n",
       "      <td>4148810</td>\n",
       "      <td>172.286883</td>\n",
       "      <td>169.164732</td>\n",
       "      <td>59.726591</td>\n",
       "      <td>65.335760</td>\n",
       "      <td>59.757395</td>\n",
       "      <td>172.286883</td>\n",
       "      <td>176.468678</td>\n",
       "      <td>168.105088</td>\n",
       "      <td>1.380488</td>\n",
       "      <td>1.426499</td>\n",
       "      <td>1.171066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 13:30:00-04:00</th>\n",
       "      <td>173.304993</td>\n",
       "      <td>173.879898</td>\n",
       "      <td>173.100006</td>\n",
       "      <td>173.179993</td>\n",
       "      <td>173.179993</td>\n",
       "      <td>3964263</td>\n",
       "      <td>172.449133</td>\n",
       "      <td>169.329932</td>\n",
       "      <td>58.333222</td>\n",
       "      <td>61.997490</td>\n",
       "      <td>59.018155</td>\n",
       "      <td>172.449133</td>\n",
       "      <td>176.503188</td>\n",
       "      <td>168.395077</td>\n",
       "      <td>1.272460</td>\n",
       "      <td>1.395692</td>\n",
       "      <td>1.143125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 14:30:00-04:00</th>\n",
       "      <td>173.199997</td>\n",
       "      <td>173.345001</td>\n",
       "      <td>172.559998</td>\n",
       "      <td>172.729996</td>\n",
       "      <td>172.729996</td>\n",
       "      <td>4786101</td>\n",
       "      <td>172.590633</td>\n",
       "      <td>169.483732</td>\n",
       "      <td>51.754316</td>\n",
       "      <td>56.604709</td>\n",
       "      <td>55.525482</td>\n",
       "      <td>172.590633</td>\n",
       "      <td>176.472827</td>\n",
       "      <td>168.708438</td>\n",
       "      <td>1.137425</td>\n",
       "      <td>1.344038</td>\n",
       "      <td>1.117545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-04-30 15:30:00-04:00</th>\n",
       "      <td>172.740005</td>\n",
       "      <td>172.940002</td>\n",
       "      <td>170.020004</td>\n",
       "      <td>170.089996</td>\n",
       "      <td>170.089996</td>\n",
       "      <td>11784580</td>\n",
       "      <td>172.562132</td>\n",
       "      <td>169.582232</td>\n",
       "      <td>1.164594</td>\n",
       "      <td>37.084044</td>\n",
       "      <td>40.414608</td>\n",
       "      <td>172.562132</td>\n",
       "      <td>176.508441</td>\n",
       "      <td>168.615823</td>\n",
       "      <td>0.808067</td>\n",
       "      <td>1.236844</td>\n",
       "      <td>1.246291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3306 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Open        High         Low       Close  \\\n",
       "Datetime                                                                    \n",
       "2022-06-10 09:30:00-04:00  140.190002  140.759995  137.460007  137.490005   \n",
       "2022-06-10 10:30:00-04:00  137.489899  138.539001  137.270004  137.399994   \n",
       "2022-06-10 11:30:00-04:00  137.410995  138.070007  137.289993  137.975006   \n",
       "2022-06-10 12:30:00-04:00  137.979996  138.210007  137.460007  138.089996   \n",
       "2022-06-10 13:30:00-04:00  138.089996  138.740005  137.729996  137.960007   \n",
       "...                               ...         ...         ...         ...   \n",
       "2024-04-30 11:30:00-04:00  173.869904  174.199905  173.604996  173.836594   \n",
       "2024-04-30 12:30:00-04:00  173.839996  173.929993  173.220001  173.275299   \n",
       "2024-04-30 13:30:00-04:00  173.304993  173.879898  173.100006  173.179993   \n",
       "2024-04-30 14:30:00-04:00  173.199997  173.345001  172.559998  172.729996   \n",
       "2024-04-30 15:30:00-04:00  172.740005  172.940002  170.020004  170.089996   \n",
       "\n",
       "                            Adj Close    Volume      SMA_20      SMA_50  \\\n",
       "Datetime                                                                  \n",
       "2022-06-10 09:30:00-04:00  137.490005  23421485  146.779439  147.263031   \n",
       "2022-06-10 10:30:00-04:00  137.399994  13497913  146.285439  147.027887   \n",
       "2022-06-10 11:30:00-04:00  137.975006   7736991  145.775689  146.813787   \n",
       "2022-06-10 12:30:00-04:00  138.089996   6411832  145.242439  146.614387   \n",
       "2022-06-10 13:30:00-04:00  137.960007   7293856  144.708189  146.406943   \n",
       "...                               ...       ...         ...         ...   \n",
       "2024-04-30 11:30:00-04:00  173.836594   3446845  172.079618  168.986474   \n",
       "2024-04-30 12:30:00-04:00  173.275299   4148810  172.286883  169.164732   \n",
       "2024-04-30 13:30:00-04:00  173.179993   3964263  172.449133  169.329932   \n",
       "2024-04-30 14:30:00-04:00  172.729996   4786101  172.590633  169.483732   \n",
       "2024-04-30 15:30:00-04:00  170.089996  11784580  172.562132  169.582232   \n",
       "\n",
       "                                  %K         %D        RSI   BB_Middle  \\\n",
       "Datetime                                                                 \n",
       "2022-06-10 09:30:00-04:00   0.246150   0.429504  15.611410  146.779439   \n",
       "2022-06-10 10:30:00-04:00   1.054255   0.754015  15.499934  146.285439   \n",
       "2022-06-10 11:30:00-04:00   6.109205   2.469870  19.456611  145.775689   \n",
       "2022-06-10 12:30:00-04:00   7.321360   4.828273  20.260719  145.242439   \n",
       "2022-06-10 13:30:00-04:00   6.160738   6.530434  20.017429  144.708189   \n",
       "...                              ...        ...        ...         ...   \n",
       "2024-04-30 11:30:00-04:00  67.932656  70.962925  64.151716  172.079618   \n",
       "2024-04-30 12:30:00-04:00  59.726591  65.335760  59.757395  172.286883   \n",
       "2024-04-30 13:30:00-04:00  58.333222  61.997490  59.018155  172.449133   \n",
       "2024-04-30 14:30:00-04:00  51.754316  56.604709  55.525482  172.590633   \n",
       "2024-04-30 15:30:00-04:00   1.164594  37.084044  40.414608  172.562132   \n",
       "\n",
       "                             BB_Upper    BB_Lower      MACD  MACD_Signal  \\\n",
       "Datetime                                                                   \n",
       "2022-06-10 09:30:00-04:00  152.291020  141.267858 -1.466908    -0.547692   \n",
       "2022-06-10 10:30:00-04:00  153.137159  139.433719 -1.930529    -0.824260   \n",
       "2022-06-10 11:30:00-04:00  153.457423  138.093955 -2.225894    -1.104586   \n",
       "2022-06-10 12:30:00-04:00  153.483210  137.001667 -2.422766    -1.368222   \n",
       "2022-06-10 13:30:00-04:00  153.371900  136.044477 -2.559770    -1.606532   \n",
       "...                               ...         ...       ...          ...   \n",
       "2024-04-30 11:30:00-04:00  176.451501  167.707735  1.488587     1.438002   \n",
       "2024-04-30 12:30:00-04:00  176.468678  168.105088  1.380488     1.426499   \n",
       "2024-04-30 13:30:00-04:00  176.503188  168.395077  1.272460     1.395692   \n",
       "2024-04-30 14:30:00-04:00  176.472827  168.708438  1.137425     1.344038   \n",
       "2024-04-30 15:30:00-04:00  176.508441  168.615823  0.808067     1.236844   \n",
       "\n",
       "                                ATR  \n",
       "Datetime                             \n",
       "2022-06-10 09:30:00-04:00  1.526065  \n",
       "2022-06-10 10:30:00-04:00  1.507703  \n",
       "2022-06-10 11:30:00-04:00  1.455725  \n",
       "2022-06-10 12:30:00-04:00  1.405316  \n",
       "2022-06-10 13:30:00-04:00  1.377080  \n",
       "...                             ...  \n",
       "2024-04-30 11:30:00-04:00  1.206533  \n",
       "2024-04-30 12:30:00-04:00  1.171066  \n",
       "2024-04-30 13:30:00-04:00  1.143125  \n",
       "2024-04-30 14:30:00-04:00  1.117545  \n",
       "2024-04-30 15:30:00-04:00  1.246291  \n",
       "\n",
       "[3306 rows x 17 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out example dataframe\n",
    "full_stock_data['AAPL']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the means and std for normalization\n",
    "means = pd.DataFrame()\n",
    "std_devs = pd.DataFrame()\n",
    "\n",
    "for ticker, df in full_stock_data.items():\n",
    "    mean = df.mean()\n",
    "    std_dev = df.std()\n",
    "\n",
    "    means[ticker] = mean\n",
    "    std_devs[ticker] = std_dev\n",
    "\n",
    "means.to_csv('train_hourly_mean.csv')\n",
    "std_devs.to_csv('train_hourly_std_dev.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KKr7IGNtbl_E"
   },
   "source": [
    "# Creating/Training the LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "knwU22R6tv_4"
   },
   "outputs": [],
   "source": [
    "# Importing relevant libraries for the training of the LSTM\n",
    "import sklearn.preprocessing as sklp\n",
    "import sklearn.model_selection as sklm\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "T6quQgu7xCTw"
   },
   "outputs": [],
   "source": [
    "# Importing the datasets we use throughout our code -> see specs in the lstm_datasets.py file\n",
    "from lstm_datasets import TimeSeriesDataset, ValTimeSeriesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "ILGNkZGMuBby"
   },
   "outputs": [],
   "source": [
    "stock_data = full_stock_data\n",
    "tickers = list(stock_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "PtIOEO66H96V"
   },
   "outputs": [],
   "source": [
    "# In case we train on GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weP9KGeEwgkH"
   },
   "source": [
    "## LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mkNm0qdRwgRG"
   },
   "outputs": [],
   "source": [
    "# Import model, see specs in lstm.py file\n",
    "from lstm import LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYTZSJJLyPAT"
   },
   "source": [
    "### Train & Validation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "L7VOP2b5x8mh"
   },
   "outputs": [],
   "source": [
    "# The validation loop given a criterion and dataloader\n",
    "def val_on_stock(model, val_dataloader, criterion):\n",
    "  # Get val loss\n",
    "  val_running_loss = 0\n",
    "  tot = 0\n",
    "\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "    for i, (inputs, labels) in enumerate(val_dataloader):\n",
    "        labels = labels.view(-1, 1).to(device)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        val_running_loss += loss.item()\n",
    "        tot += 1\n",
    "\n",
    "  return val_running_loss/tot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "nq0pV4SVN4BI"
   },
   "outputs": [],
   "source": [
    "# The training loop given a criterion and dataloader\n",
    "def train_on_stock(model, val_dataloader, train_dataloader, criterion, epochs, print_epochs=False):\n",
    "  # To store the losses\n",
    "  train_loss_arr = []\n",
    "  val_loss_arr = []\n",
    "  best_loss_val = float('inf')\n",
    "\n",
    "  # Store best_model\n",
    "  best_model = None\n",
    "\n",
    "  #Initialize optimizer\n",
    "  optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  # Training loop\n",
    "  for epoch in range(epochs):\n",
    "\n",
    "      running_loss = 0.0\n",
    "      tot = 0\n",
    "\n",
    "      model.train()\n",
    "\n",
    "      for i, (inputs, labels) in enumerate(train_dataloader):\n",
    "\n",
    "        labels = labels.view(-1, 1).to(device)\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(inputs) # Forward pass\n",
    "        loss = criterion(preds, labels)\n",
    "\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step() # Gradient step\n",
    "\n",
    "        tot += 1\n",
    "\n",
    "      val_loss = val_on_stock(model, val_dataloader, criterion) # Getting val loss\n",
    "      train_loss = running_loss/tot\n",
    "\n",
    "      train_loss_arr.append(train_loss)\n",
    "      val_loss_arr.append(val_loss)\n",
    "      if best_model==None or best_val_loss>val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        best_model = copy.deepcopy(model.state_dict())\n",
    "\n",
    "      if print_epochs:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}: Training loss = {round(train_loss, 5)}, Validation loss = {round(val_loss, 5)}\")\n",
    "\n",
    "  return train_loss_arr, val_loss_arr, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OXrWAllTFAZv"
   },
   "source": [
    "## Optimal hyperparameters used to train all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "g5lPB8gyE_2r"
   },
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "num_layers = 4\n",
    "hidden_size = 100\n",
    "input_size = 17\n",
    "\n",
    "batch_size = 20\n",
    "\n",
    "learning_rate = 1e-5\n",
    "lstm_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OxkwlvRlEzWE"
   },
   "source": [
    "## Training to look forward for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "sRZl-A1vWPv6"
   },
   "outputs": [],
   "source": [
    "#params for dataset\n",
    "b = 1\n",
    "f = 1\n",
    "\n",
    "n_lags = 8 * 30 * b #look back n MONTHS: hours/market-day * days * quantity\n",
    "forecast_horizon = 8 * f #look ahead f days:\n",
    "\n",
    "# Creating the val/train split used for all stocks\n",
    "tot = int(sum([len(d)-n_lags-forecast_horizon+1 for d in full_stock_data.values()])/len(full_stock_data))\n",
    "train_split, val_split = tot - int(tot*0.2), int(tot*0.2)\n",
    "indices = list(range(tot))\n",
    "train_indices = indices[:train_split]\n",
    "val_indices = indices[train_split:]\n",
    "\n",
    "stock_datastruct = {}\n",
    "\n",
    "# Creating datasets\n",
    "for key, value in full_stock_data.items():\n",
    "  mean = value.mean()\n",
    "  std_dev = value.std()\n",
    "  value = (value - mean) / std_dev\n",
    "\n",
    "  val_dataset = TimeSeriesDataset(key, value, n_lags, forecast_horizon, indices=val_indices)\n",
    "  train_dataset = TimeSeriesDataset(key, value, n_lags, forecast_horizon, indices=train_indices)\n",
    "\n",
    "  temp = {'val_dataset':val_dataset, 'train_dataset':train_dataset, 'mean':mean, 'std':std_dev}\n",
    "  stock_datastruct[val_dataset.ticker] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "O62mJnR7x_My"
   },
   "outputs": [],
   "source": [
    "# Creating the loss\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Initialize LSTM models for each stock\n",
    "for ticker in stock_datastruct.keys():\n",
    "  stock_datastruct[ticker]['LSTM'] = LSTM(num_layers, input_size, hidden_size, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "-T-A3tdigoqy"
   },
   "outputs": [],
   "source": [
    "# Creating dataloaders\n",
    "for ticker in stock_datastruct.keys():\n",
    "    val_dataloader = DataLoader(stock_datastruct[ticker]['val_dataset'], batch_size=batch_size, shuffle=False)\n",
    "    train_dataloader = DataLoader(stock_datastruct[ticker]['train_dataset'], batch_size=batch_size, shuffle=True)\n",
    "    stock_datastruct[ticker]['val_dataloader'] = val_dataloader\n",
    "    stock_datastruct[ticker]['train_dataloader'] = train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q4VVbzaiGg7f"
   },
   "outputs": [],
   "source": [
    "# Making the directory where we will be storing all the models for each ticker\n",
    "!rm -r /content/LSTM_weights\n",
    "!mkdir LSTM_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RQ8k2LQxFxvj",
    "outputId": "29b393b3-8ea2-437f-ced0-eb7d0d9c0f16",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dictionary where we will be storing training losses and validation losses\n",
    "loss_dict = dict()\n",
    "loss_dict['val_loss'] = dict()\n",
    "loss_dict['train_loss'] = dict()\n",
    "loss_dict['best_val'] = dict()\n",
    "\n",
    "# Iterate through each ticker, train the model, save the weights and save all loses in a file\n",
    "for ticker in stock_datastruct.keys():\n",
    "    stock = stock_datastruct[ticker]\n",
    "    model = stock['LSTM']\n",
    "    val_dataloader = stock['val_dataloader']\n",
    "    train_dataloader = stock['train_dataloader']\n",
    "\n",
    "    # Train this lticker's lstm\n",
    "    lstm_train_loss, lstm_val_loss, best_model = train_on_stock(model, val_dataloader, train_dataloader, criterion, lstm_epochs)\n",
    "\n",
    "    # Printing ticker's best val loss\n",
    "    model.load_state_dict(best_model)\n",
    "    best_val_loss = val_on_stock(model, val_dataloader, criterion)\n",
    "    print(f\"Test/Validation loss for {ticker} after training : {round(best_val_loss, 5)}\")\n",
    "\n",
    "    # Record results\n",
    "    loss_dict['val_loss'][ticker] = lstm_val_loss\n",
    "    loss_dict['train_loss'][ticker] = lstm_train_loss\n",
    "    loss_dict['best_val'][ticker] = best_val_loss\n",
    "\n",
    "    # Save the model for this ticker\n",
    "    torch.save(best_model, \"LSTM_weights/\"+ticker+\".pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rklENCuyO_CF",
    "outputId": "448e5506-8691-44e5-fbdc-169882fb52d7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zipping the weights folder to download\n",
    "!zip -r LSTM_weights.zip LSTM_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGbhKixaSQ8G"
   },
   "outputs": [],
   "source": [
    "# Saving the loss_dict which has all train/val stats\n",
    "file_path = \"run_stats_day.json\"\n",
    "with open(file_path, \"w\") as json_file:\n",
    "    json.dump(loss_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict future changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Go in the lstm_predict file to see specs\n",
    "from lstm_predict import predict\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UtsZBX3YtUES",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "[*********************100%%**********************]  1 of 1 completed\n",
      "Predicting:   2%|█▏                                                                     | 1/57 [00:03<03:18,  3.55s/it]"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "timestep = \"d\"\n",
    "start_date = \"2024-05-18\"\n",
    "\n",
    "# Function\n",
    "preds = predict(timestep, start_date)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "timestep = \"w\"\n",
    "start_date = '2023-12-29'\n",
    "\n",
    "# Function\n",
    "preds = predict(timestep, start_date)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs\n",
    "timestep = \"m\"\n",
    "start_date = '2023-12-29'\n",
    "\n",
    "# Function\n",
    "preds = predict(timestep, start_date)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "timestep = \"y\"\n",
    "start_date = '2023-12-25'\n",
    "\n",
    "# Function\n",
    "preds = predict(timestep, start_date)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
